<!doctype html><html><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><title>Superintelligence: Paths, Dangers and Strategies by Nick Bostrom</title><meta name=description content="Embedded Software Engineer"><meta name=author content="Chris Woodall"><link href="https://fonts.googleapis.com/css2?family=Inconsolata:wght@400;700&display=swap" rel=stylesheet><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/css/bootstrap.min.css integrity=sha384-TX8t27EcRE3e/ihU7zmQxVncDAy5uIKz4rEkgIXeMed4M0jlfIDPvg6uqKI2xXr2 crossorigin=anonymous><link rel=stylesheet href=/sass/researcher.min.css><style>img{max-width:100%}</style><link rel=icon type=image/ico href=/favicon.ico></head><body><div class="container mt-5"><nav class="navbar navbar-expand-sm flex-column flex-sm-row text-nowrap p-0"><a class="navbar-brand mx-0 mr-sm-auto" href=/>Chris Woodall</a><div class="navbar-nav flex-row flex-wrap justify-content-center"><a class="nav-item nav-link" href=/now>Now</a>
<span class="nav-item navbar-text mx-1">/</span>
<a class="nav-item nav-link" href=/posts>Blog</a>
<span class="nav-item navbar-text mx-1">/</span>
<a class="nav-item nav-link" href=/climbing>Climb</a>
<span class="nav-item navbar-text mx-1">/</span>
<a class="nav-item nav-link" href=/music>Music</a>
<span class="nav-item navbar-text mx-1">/</span>
<a class="nav-item nav-link" href=/projects>Projects</a>
<span class="nav-item navbar-text mx-1">/</span>
<a class="nav-item nav-link" href=/reading>Read</a>
<span class="nav-item navbar-text mx-1">/</span>
<a class="nav-item nav-link" href=/resume.pdf>Resume</a></div></nav></div><hr><div id=content><div class=container><h1 align=center>Superintelligence: Paths, Dangers and Strategies by Nick Bostrom</h1><div align=center>Chris Woodall | 2016-09-24</div><img src=/img/books/superintelligence.jpg><br><p>Nick Bostrom&rsquo;s <a href=https://www.amazon.com/Superintelligence-Dangers-Strategies-Nick-Bostrom/dp/1501227742><em>Superintelligence: Paths, Dangers and Strategies</em></a> inspects and dissects the topic of Superintelligence. First, laying out different possible paths to super intelligence and then discussing how these different paths might effect humanity, or might occur. It then discusses the dynamics of a singleton AI and later a multi-polar world of interacting AIs. However, Bostrom&rsquo;s real point throughout this book is not just how one might build an AI. But how one might build and control an AI safely, namely the control problem (which I just found out has a <a href=https://www.reddit.com/r/ControlProblem/>subreddit</a> dedicated to it). On one hand Bostrom suggests that human-brain emulation might lead to a super intelligence that naturally shares our values, and with proper selection, there is a small chance this solves the control problem. However, more likely it means we have no real control over what happens. On the other hand, the challenge of building an AI which is set up to be flexible enough to grow with humanity, being benevolent the whole time, and be provably this way is a major challenge in its own right.</p><p>The book was eye opening to me as an engineer. Not only does Bostrom really dig into superintelligence, but the ethics the project that designs it should have. Namely, a focus on safety and a compassionate attitude towards humanity. Also enlightening was the idea that the best way to specify most of the subsystems an AI needs might be indirectly, which at first seemed counter intuitive to me. This is do to the fact that a sufficiently smart AI (or human for that matter), if it has a goal to improve itself does not need to start life with a perfect system, as outlined by this quote:</p><blockquote><p>Rather, our focus should be on creating a highly reliable design, one that can be trusted to retain enough sanity to recognize its own failings. An imperfect superintelligence, whose fundamentals are sound, would gradually repair itself; and having done so, it would exert as much beneficial optimization power on the world as if it had been perfect from the outset.</p><p>— <em>Nick Bostrom</em></p></blockquote><p>It was an enjoyable read and I left the book with a wonder and awe at the problems of AI. It is a little scary, but I think I agree with Bostrom&rsquo;s thesis that is not <em>if</em> but <em>when</em> and I for one would rather try to contribute to a benevolent AI, than let the world get swallowed by an ignorant, sophistic or power hungry AI. I leave you with this quote:</p><blockquote><p>The point of superintelligence is not to pander to human preconceptions but to make mincemeat out of our ignorance and folly.</p><p>— <em>Nick Bostrom</em></p></blockquote></div></div><div id=footer class=mb-5><hr><div class="container text-center"><a href=https://github.com/ojroques/hugo-researcher><small>By Chris Woodall</small></a></div></div></body></html>